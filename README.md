# Applied machine-learning for science

ðŸ’» Material for a course on applied machine-learning for scientists taught at
EPFL in spring 2017.

ðŸš§ This is still under heavy construction ðŸš§


# Outline

The course consists of six two hour lectures, followed by one hour to discuss
the weeks homework assignment.

Current bucket list of topics to cover ((~) denotes: short introduction to):

1. [General problem statement and introduction](https://github.com/wildtreetech/advanced-comp-2017/tree/master/01-introduction)
2. [Ensembles of trees: forests and gradient boosting](https://github.com/wildtreetech/advanced-comp-2017/tree/master/02-trees)
3. Neural networks: convolutions aren't convoluted
4. Model selection and evaluation: predict future performance
5. PCA and t-SNE: lower dimensional embeddings and visualisation
5. Bayesian optimisation for hyper-parameter tuning (~)
6. Meet a GAN: cops and robbers for neural networks (~)
7. Fine tuning the state of the art: standing on the shoulder of giants (~)
8. Probabilistic datastructures: a bonus lecture


# Course projects

Take a look at possible [course projects](projects.md).


# Technicalities, installing, running code

All the code will be written in python. We will make use of the scientific
python stack:

* python v3.6
* numpy v1.12.1
* scikit-learn v0.18.1
* keras
* matplotlib v2.0.0
* jupyter v5.0.0

All work submitted for credit has to run with these dependencies only.

[Instructions on installing](install.md) on windows, mac and linux.


# License

Heavily inspired by [ESL], [ISL], [Introduction to machine-learning with
python][IML], and lecture notes by [Gilles Louppe][glouppe].

All original work is licensed under [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/).

[ISL]: http://www-bcf.usc.edu/~gareth/ISL/
[ESL]: https://statweb.stanford.edu/~tibs/ElemStatLearn/
[IML]: http://shop.oreilly.com/product/0636920030515.do
[glouppe]: https://github.com/glouppe
